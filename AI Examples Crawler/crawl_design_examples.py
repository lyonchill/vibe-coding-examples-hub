"""
å°ˆé–€çˆ¬å– UI/UX Design, Design System, Web Design ç›¸é—œçš„ vibe-coding æ¡ˆä¾‹
å°ˆæ³¨åœ¨éå»ä¸‰å€‹æœˆå…§ï¼Œä½¿ç”¨ Cursor, Figma Make/MCP ç­‰å·¥å…·å¯¦éš›æ§‹å»ºçš„æ¡ˆä¾‹
"""
import json
import sys
from pathlib import Path
from datetime import datetime, timedelta
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent))
from ai_examples_crawler import AIExamplesCrawler

load_dotenv()

# å°ˆæ³¨æ–¼è¨­è¨ˆç›¸é—œçš„é—œéµå­—
DESIGN_YOUTUBE_KEYWORDS = [
    "cursor design system",
    "cursor UI design",
    "cursor web design",
    "figma mcp cursor",
    "figma make design system",
    "figma make icon library",
    "vibe coding design system",
    "vibe coding UI UX",
    "no-code design system",
    "cursor build design",
    "AI design system",
    "cursor figma plugin",
    "vibe coding web design",
    "cursor UI components",
    "figma make documentation",
]

DESIGN_LINKEDIN_KEYWORDS = [
    "Figma Make design system",
    "Figma Make icon library",
    "cursor design system",
    "figma mcp cursor",
    "vibe coding UI design",
    "cursor UI UX",
    "no-code design system",
    "figma make plugin",
    "cursor build design",
    "AI design system",
    "vibe coding web design",
    "cursor figma",
    "design system with cursor",
    "figma make documentation",
    "cursor UI components",
]

def crawl_design_examples():
    """çˆ¬å–è¨­è¨ˆç›¸é—œçš„ vibe-coding æ¡ˆä¾‹"""
    print("=" * 70)
    print("çˆ¬å– UI/UX Design, Design System, Web Design ç›¸é—œæ¡ˆä¾‹")
    print("=" * 70)
    print(f"æ™‚é–“ç¯„åœ: éå»ä¸‰å€‹æœˆï¼ˆ90å¤©ï¼‰")
    print(f"ç›®æ¨™: 15å€‹ YouTube + 15å€‹ LinkedIn")
    print()
    
    crawler = AIExamplesCrawler()
    
    # ä¿®æ”¹ YouTube æœç´¢æ™‚é–“ç¯„åœç‚º90å¤©ï¼ˆä½¿ç”¨åŸå§‹æ–¹æ³•ä½†ä¿®æ”¹æ™‚é–“ï¼‰
    original_search_youtube = crawler.search_youtube
    
    def search_youtube_90days(query: str, max_results: int = 5):
        """æœç´¢éå»90å¤©çš„ YouTube å½±ç‰‡"""
        # ä½¿ç”¨åŸå§‹æ–¹æ³•ï¼Œä½†è‡¨æ™‚ä¿®æ”¹æ™‚é–“ç¯„åœ
        import os
        from datetime import timedelta
        
        # è‡¨æ™‚ä¿®æ”¹ crawler çš„æ™‚é–“ç¯„åœ
        original_method = crawler.search_youtube.__func__
        
        # å‰µå»ºä¸€å€‹åŒ…è£å‡½æ•¸
        def wrapper(self, query: str, max_results: int = 5):
            url = "https://www.googleapis.com/youtube/v3/search"
            
            # éå»90å¤©
            published_after = (datetime.now() - timedelta(days=90)).isoformat() + "Z"
            
            YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY", "")
            
            params = {
                'part': 'snippet',
                'q': query,
                'type': 'video',
                'order': 'viewCount',
                'maxResults': max_results,
                'publishedAfter': published_after,
                'key': YOUTUBE_API_KEY
            }
            
            try:
                import requests
                response = requests.get(url, params=params)
                response.raise_for_status()
                data = response.json()
                
                results = []
                video_ids = []
                for item in data.get('items', []):
                    video_id = item['id']['videoId']
                    video_ids.append(video_id)
                
                # ç²å–è¦–é »çµ±è¨ˆä¿¡æ¯
                if video_ids:
                    stats_url = "https://www.googleapis.com/youtube/v3/videos"
                    stats_params = {
                        'part': 'statistics,snippet',
                        'id': ','.join(video_ids),
                        'key': YOUTUBE_API_KEY
                    }
                    stats_response = requests.get(stats_url, params=stats_params)
                    stats_data = stats_response.json()
                    
                    stats_dict = {}
                    for item in stats_data.get('items', []):
                        stats_dict[item['id']] = item['statistics']
                    
                    for item in data.get('items', []):
                        video_id = item['id']['videoId']
                        snippet = item['snippet']
                        stats = stats_dict.get(video_id, {})
                        
                        results.append({
                            'title': snippet['title'],
                            'description': snippet['description'],
                            'url': f"https://www.youtube.com/watch?v={video_id}",
                            'thumbnail': snippet['thumbnails'].get('high', {}).get('url', ''),
                            'creator': snippet['channelTitle'],
                            'creator_url': f"https://www.youtube.com/channel/{snippet['channelId']}",
                            'platform': 'YouTube',
                            'published_at': snippet['publishedAt'],
                            'view_count': int(stats.get('viewCount', 0)),
                            'like_count': int(stats.get('likeCount', 0)),
                            'comment_count': int(stats.get('commentCount', 0))
                        })
                
                return results
                
            except Exception as e:
                print(f"YouTube search error for '{query}': {e}")
                return []
        
        return wrapper(crawler, query, max_results)
    
    # ä½¿ç”¨åŸå§‹æ–¹æ³•ä½†æ‰‹å‹•è¨­ç½®æ™‚é–“ç¯„åœ
    import types
    crawler.search_youtube = types.MethodType(search_youtube_90days, crawler)
    
    # æœå°‹ YouTubeï¼ˆä½¿ç”¨åŸå§‹æ–¹æ³•ï¼Œä½†ä¿®æ”¹ç‚º90å¤©ï¼‰
    print("ğŸ” æœå°‹ YouTube...")
    print("   æ³¨æ„: ä½¿ç”¨åŸå§‹ search_youtube æ–¹æ³•ï¼Œæ™‚é–“ç¯„åœæ”¹ç‚º90å¤©")
    all_youtube_results = []
    
    # è‡¨æ™‚ä¿®æ”¹ search_youtube çš„æ™‚é–“ç¯„åœ
    original_method = crawler.search_youtube
    import types
    
    def search_youtube_90days(self, query: str, max_results: int = 5):
        """æœç´¢éå»90å¤©çš„ YouTube å½±ç‰‡"""
        url = "https://www.googleapis.com/youtube/v3/search"
        
        # éå»90å¤©
        published_after = (datetime.now() - timedelta(days=90)).isoformat() + "Z"
        
        import os
        import requests
        YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY", "")
        
        params = {
            'part': 'snippet',
            'q': query,
            'type': 'video',
            'order': 'viewCount',
            'maxResults': max_results,
            'publishedAfter': published_after,
            'key': YOUTUBE_API_KEY
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            results = []
            video_ids = []
            for item in data.get('items', []):
                video_id = item['id']['videoId']
                video_ids.append(video_id)
            
            # ç²å–è¦–é »çµ±è¨ˆä¿¡æ¯
            if video_ids:
                stats_url = "https://www.googleapis.com/youtube/v3/videos"
                stats_params = {
                    'part': 'statistics,snippet',
                    'id': ','.join(video_ids),
                    'key': YOUTUBE_API_KEY
                }
                stats_response = requests.get(stats_url, params=stats_params)
                stats_data = stats_response.json()
                
                stats_dict = {}
                for item in stats_data.get('items', []):
                    stats_dict[item['id']] = item['statistics']
                
                for item in data.get('items', []):
                    video_id = item['id']['videoId']
                    snippet = item['snippet']
                    stats = stats_dict.get(video_id, {})
                    
                    results.append({
                        'title': snippet['title'],
                        'description': snippet['description'],
                        'url': f"https://www.youtube.com/watch?v={video_id}",
                        'thumbnail': snippet['thumbnails'].get('high', {}).get('url', ''),
                        'creator': snippet['channelTitle'],
                        'creator_url': f"https://www.youtube.com/channel/{snippet['channelId']}",
                        'platform': 'YouTube',
                        'published_at': snippet['publishedAt'],
                        'view_count': int(stats.get('viewCount', 0)),
                        'like_count': int(stats.get('likeCount', 0)),
                        'comment_count': int(stats.get('commentCount', 0))
                    })
            
            return results
            
        except Exception as e:
            print(f"    âš ï¸  YouTube search error: {e}")
            return []
    
    crawler.search_youtube = types.MethodType(search_youtube_90days, crawler)
    
    for keyword in DESIGN_YOUTUBE_KEYWORDS[:10]:  # é™åˆ¶å‰10å€‹é—œéµå­—
        print(f"  é—œéµå­—: {keyword}")
        results = crawler.search_youtube(keyword, max_results=3)
        all_youtube_results.extend(results)
        print(f"    æ‰¾åˆ° {len(results)} å€‹çµæœ")
    
    # å»é‡ YouTube
    seen_youtube_urls = set()
    unique_youtube = []
    for result in all_youtube_results:
        if result['url'] not in seen_youtube_urls:
            seen_youtube_urls.add(result['url'])
            unique_youtube.append(result)
    
    # æŒ‰è§€çœ‹æ•¸æ’åº
    unique_youtube.sort(key=lambda x: x.get('view_count', 0), reverse=True)
    
    print(f"\nâœ… YouTube: æ‰¾åˆ° {len(unique_youtube)} å€‹å”¯ä¸€çµæœ")
    
    # æœå°‹ LinkedIn
    print("\nğŸ” æœå°‹ LinkedIn...")
    all_linkedin_results = []
    for keyword in DESIGN_LINKEDIN_KEYWORDS:
        print(f"  é—œéµå­—: {keyword}")
        results = crawler.search_linkedin_via_serpapi(keyword, max_results=3)
        all_linkedin_results.extend(results)
        print(f"    æ‰¾åˆ° {len(results)} å€‹çµæœ")
    
    # å»é‡ LinkedIn
    seen_linkedin_urls = set()
    unique_linkedin = []
    for result in all_linkedin_results:
        if result['url'] not in seen_linkedin_urls:
            seen_linkedin_urls.add(result['url'])
            unique_linkedin.append(result)
    
    print(f"\nâœ… LinkedIn: æ‰¾åˆ° {len(unique_linkedin)} å€‹å”¯ä¸€çµæœ")
    
    # ä½¿ç”¨ AI åˆ†æï¼ˆå°ˆæ³¨æ–¼è¨­è¨ˆç›¸é—œï¼‰
    print("\nğŸ¤– AI åˆ†æä¸­...")
    print("   å°ˆæ³¨æ–¼: UI/UX Design, Design System, Web Design")
    print("   è¦æ±‚: å¿…é ˆç¢ºå¯¦ä½¿ç”¨ vibe-coding toolsï¼ˆå¦‚ Cursor, Figma Makeï¼‰")
    
    design_examples = []
    
    # åˆ†æ YouTubeï¼ˆå–å‰15å€‹ï¼‰
    for i, result in enumerate(unique_youtube[:15], 1):
        print(f"\n[{i}/15] YouTube: {result['title'][:60]}...")
        try:
            analysis = crawler.analyze_content_with_ai(result)
            
            # æª¢æŸ¥æ˜¯å¦èˆ‡è¨­è¨ˆç›¸é—œ
            is_design_related = any(tag in ['Design', 'Design System', 'UI/UX', 'Web Design'] 
                                   for tag in analysis.get('category_tags', []))
            
            # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨äº†è¨­è¨ˆç›¸é—œçš„å·¥å…·
            tools = analysis.get('ai_tools_used', [])
            has_design_tool = any(tool in ['Cursor', 'Figma', 'Figma Make', 'Figma MCP'] 
                                for tool in tools)
            
            # æª¢æŸ¥æ˜¯å¦ç¢ºå¯¦æ§‹å»ºäº†é …ç›®ï¼ˆä¸æ˜¯å–®ç´”è¨è«–ï¼‰
            is_real_project = analysis.get('is_real_project', False)
            project_evidence = analysis.get('project_evidence', '')
            has_build_evidence = 'build' in project_evidence.lower() or \
                               'create' in project_evidence.lower() or \
                               'made' in project_evidence.lower() or \
                               'generated' in project_evidence.lower()
            
            if (is_design_related or has_design_tool) and (is_real_project or has_build_evidence):
                example = crawler.create_example_from_content(result, analysis)
                example['source_platform'] = 'YouTube'
                design_examples.append(example)
                print(f"  âœ… ç¬¦åˆæ¢ä»¶ï¼Œå·²åŠ å…¥")
            else:
                print(f"  âš ï¸  ä¸ç¬¦åˆæ¢ä»¶ï¼ˆè¨­è¨ˆç›¸é—œ: {is_design_related}, å·¥å…·: {has_design_tool}, å¯¦éš›é …ç›®: {is_real_project or has_build_evidence}ï¼‰")
        except Exception as e:
            print(f"  âŒ åˆ†æéŒ¯èª¤: {e}")
    
    # åˆ†æ LinkedInï¼ˆå–å‰15å€‹ï¼‰
    for i, result in enumerate(unique_linkedin[:15], 1):
        print(f"\n[{i}/15] LinkedIn: {result['title'][:60]}...")
        try:
            # LinkedIn ä½¿ç”¨ç°¡åŒ–åˆ†æï¼ˆé¿å… API quota å•é¡Œï¼‰
            from add_linkedin_simple import create_simple_linkedin_example
            example = create_simple_linkedin_example(result)
            
            # æª¢æŸ¥æ˜¯å¦èˆ‡è¨­è¨ˆç›¸é—œ
            title_desc = (example.get('title', '') + ' ' + example.get('description', '')).lower()
            
            # æ’é™¤èª¤åˆ¤ï¼šæª¢æŸ¥æ˜¯å¦æ˜¯æŒ‡é¼ æ¨™ cursor è€Œä¸æ˜¯ Cursor AI å·¥å…·
            is_mouse_cursor = any(phrase in title_desc for phrase in [
                'custom cursor', 'mouse cursor', 'cursor location', 'cursor position',
                'cursor hover', 'cursor enter', 'cursor image', 'cursor style',
                'change cursor', 'cursor icon', 'cursor design', 'mouse enter',
                'cursor location', 'based on cursor', 'cursor-based', 'cursor trigger'
            ]) and 'cursor ai' not in title_desc and 'built with cursor' not in title_desc and 'using cursor' not in title_desc
            
            if is_mouse_cursor:
                print(f"  âŒ æ’é™¤ï¼šæŒ‡çš„æ˜¯é¼ æ¨™ cursorï¼Œä¸æ˜¯ Cursor AI å·¥å…·")
                continue
            
            # å¿…é ˆåŒ…å«è¨­è¨ˆç›¸é—œé—œéµå­—
            is_design_related = any(keyword in title_desc for keyword in [
                'design system', 'ui', 'ux', 'web design', 'figma make', 'figma mcp',
                'icon library', 'component library', 'plugin', 'figma plugin',
                'built with cursor', 'cursor ai', 'cursor build', 'cursor created',
                'made with cursor', 'using cursor', 'cursor tool'
            ])
            
            # å¿…é ˆä½¿ç”¨äº† vibe-coding å·¥å…·
            tools = example.get('ai_tools_used', [])
            has_vibe_tool = any(tool in ['Cursor', 'Figma', 'Figma Make', 'Figma MCP', 'Claude', 'ChatGPT', 'Lovable', 'v0'] for tool in tools)
            
            # å¿…é ˆæœ‰å¯¦éš›æ§‹å»ºç”¢å“çš„è­‰æ“šï¼ˆä¸æ˜¯å–®ç´”åŠŸèƒ½å±•ç¤ºï¼‰
            has_build_evidence = any(keyword in title_desc for keyword in [
                'built', 'build', 'created', 'made', 'generate', 'generated',
                'built with', 'built a', 'made a', 'created a', 'built using',
                'made with', 'created with', 'built this', 'made this',
                'created this', 'built an', 'made an', 'created an'
            ])
            
            # æª¢æŸ¥æ˜¯å¦åªæ˜¯åŠŸèƒ½å±•ç¤ºè€Œéå¯¦éš›æ§‹å»º
            is_feature_demo_only = any(phrase in title_desc for phrase in [
                'new feature', 'introducing', 'announcement', 'update',
                'what\'s new', 'check out', 'try this', 'little experiment',
                'here\'s how', 'how to use', 'tutorial', 'guide'
            ]) and not has_build_evidence
            
            # å¿…é ˆèªªæ˜æ§‹å»ºäº†ä»€éº¼ç”¢å“/åŠŸèƒ½
            has_product_mention = any(keyword in title_desc for keyword in [
                'app', 'website', 'plugin', 'tool', 'system', 'library',
                'component', 'dashboard', 'interface', 'prototype',
                'case study', 'project', 'product'
            ])
            
            # æ’é™¤å–®ç´”è¨è«–è¨­è¨ˆçš„è²¼æ–‡
            is_just_discussion = any(keyword in title_desc for keyword in [
                'why', 'should', 'think', 'opinion', 'thoughts', 'learn',
                'tips', 'advice', 'guide to', 'how to think', 'mistake'
            ]) and not has_build_evidence
            
            if (is_design_related or has_vibe_tool) and has_build_evidence and has_product_mention and not is_feature_demo_only and not is_just_discussion:
                example['source_platform'] = 'LinkedIn'
                design_examples.append(example)
                print(f"  âœ… ç¬¦åˆæ¢ä»¶ï¼ˆè¨­è¨ˆç›¸é—œ + ä½¿ç”¨å·¥å…· + å¯¦éš›æ§‹å»ºç”¢å“ï¼‰")
            else:
                reasons = []
                if is_mouse_cursor:
                    reasons.append("é¼ æ¨™cursorèª¤åˆ¤")
                if not is_design_related and not has_vibe_tool:
                    reasons.append("éè¨­è¨ˆç›¸é—œæˆ–æœªä½¿ç”¨å·¥å…·")
                if not has_build_evidence:
                    reasons.append("ç„¡æ§‹å»ºè­‰æ“š")
                if not has_product_mention:
                    reasons.append("æœªèªªæ˜æ§‹å»ºäº†ä»€éº¼ç”¢å“")
                if is_feature_demo_only:
                    reasons.append("åƒ…ç‚ºåŠŸèƒ½å±•ç¤º")
                if is_just_discussion:
                    reasons.append("åƒ…ç‚ºè¨è«–")
                print(f"  âš ï¸  ä¸ç¬¦åˆæ¢ä»¶: {', '.join(reasons) if reasons else 'æœªçŸ¥'}")
        except Exception as e:
            print(f"  âŒ è™•ç†éŒ¯èª¤: {e}")
    
    # è¼‰å…¥ç¾æœ‰æ•¸æ“š
    data_file = Path(__file__).parent.parent / "found_examples_latest.json"
    existing_examples = []
    if data_file.exists():
        existing_examples = json.load(open(data_file, 'r', encoding='utf-8'))
    
    # åˆä½µæ•¸æ“šï¼ˆä¿ç•™ç¾æœ‰ + æ–°å¢è¨­è¨ˆç›¸é—œï¼‰
    all_examples = existing_examples + design_examples
    
    # å»é‡
    seen_urls = set()
    unique_all = []
    for ex in all_examples:
        if ex['original_url'] not in seen_urls:
            seen_urls.add(ex['original_url'])
            unique_all.append(ex)
    
    # æ’åº
    unique_all.sort(key=lambda x: (
        0 if x.get('source_platform') == 'YouTube' else 1,
        x.get('view_count', 0) if x.get('source_platform') == 'YouTube' else 0,
        x.get('relevance_score', 0)
    ), reverse=True)
    
    # ä¿å­˜
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(unique_all[:50], f, indent=2, ensure_ascii=False)
    
    youtube_count = len([x for x in design_examples if x.get('source_platform') == 'YouTube'])
    linkedin_count = len([x for x in design_examples if x.get('source_platform') == 'LinkedIn'])
    
    print(f"\n{'='*70}")
    print("âœ… å®Œæˆï¼")
    print(f"{'='*70}")
    print(f"  æ–°å¢ YouTube è¨­è¨ˆæ¡ˆä¾‹: {youtube_count}")
    print(f"  æ–°å¢ LinkedIn è¨­è¨ˆæ¡ˆä¾‹: {linkedin_count}")
    print(f"  ç¸½æ¡ˆä¾‹æ•¸: {len(unique_all)}")
    print(f"\næ•¸æ“šå·²ä¿å­˜åˆ°: {data_file}")

if __name__ == "__main__":
    crawl_design_examples()

