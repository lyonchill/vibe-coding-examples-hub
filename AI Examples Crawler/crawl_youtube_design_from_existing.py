"""
ä½¿ç”¨ç¾æœ‰æ•¸æ“šåº«ä¸­æœªåˆ†æçš„ YouTube æ¡ˆä¾‹é€²è¡Œ AI åˆ†æ
è·³é YouTube API æœå°‹ï¼Œç›´æ¥åˆ†æç¾æœ‰æ•¸æ“š
"""
import json
import sys
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent))
from ai_examples_crawler import AIExamplesCrawler

load_dotenv()

def analyze_existing_youtube_cases():
    """åˆ†æç¾æœ‰æ•¸æ“šåº«ä¸­çš„ YouTube æ¡ˆä¾‹ï¼Œæ‰¾å‡ºè¨­è¨ˆç›¸é—œçš„"""
    print("=" * 70)
    print("åˆ†æç¾æœ‰æ•¸æ“šåº«ä¸­çš„ YouTube æ¡ˆä¾‹")
    print("=" * 70)
    
    crawler = AIExamplesCrawler()
    
    # è¼‰å…¥ç¾æœ‰æ•¸æ“š
    data_file = Path(__file__).parent.parent / "found_examples_latest.json"
    if not data_file.exists():
        print("âŒ æ‰¾ä¸åˆ°æ•¸æ“šæ–‡ä»¶")
        return
    
    with open(data_file, 'r', encoding='utf-8') as f:
        existing_data = json.load(f)
    
    print(f"\nğŸ“‚ è¼‰å…¥ç¾æœ‰æ•¸æ“š: {len(existing_data)} å€‹æ¡ˆä¾‹")
    
    # æ‰¾å‡ºæ‰€æœ‰ YouTube æ¡ˆä¾‹
    youtube_cases = [x for x in existing_data if x.get('source_platform') == 'YouTube']
    print(f"  YouTube æ¡ˆä¾‹: {len(youtube_cases)} å€‹")
    
    # æ‰¾å‡ºé‚„æ²’æœ‰ primary_category æˆ–ä¸æ˜¯ Design çš„æ¡ˆä¾‹
    candidates = []
    for case in youtube_cases:
        category = case.get('primary_category', '')
        # å¦‚æœæ²’æœ‰åˆ†é¡ï¼Œæˆ–è€…æ˜¯ Development/Productivityï¼Œä½†å¯èƒ½æ˜¯è¨­è¨ˆç›¸é—œçš„
        if not category or category not in ['Design']:
            # æª¢æŸ¥æ¨™é¡Œå’Œæè¿°æ˜¯å¦å¯èƒ½èˆ‡è¨­è¨ˆç›¸é—œ
            title_desc = (case.get('title', '') + ' ' + case.get('description', '')).lower()
            has_design_keywords = any(kw in title_desc for kw in [
                'design', 'ui', 'ux', 'figma', 'component', 'icon', 'plugin',
                'cursor', 'web design', 'interface', 'prototype'
            ])
            if has_design_keywords:
                candidates.append(case)
    
    print(f"\nğŸ¯ æ‰¾åˆ° {len(candidates)} å€‹å¯èƒ½çš„è¨­è¨ˆç›¸é—œå€™é¸æ¡ˆä¾‹")
    
    if len(candidates) == 0:
        print("  æ²’æœ‰éœ€è¦åˆ†æçš„å€™é¸æ¡ˆä¾‹")
        return
    
    # æŒ‰è§€çœ‹æ•¸æ’åº
    candidates.sort(key=lambda x: x.get('view_count', 0), reverse=True)
    
    print(f"\nğŸ¤– é–‹å§‹ AI åˆ†æ...")
    print(f"   ç›®æ¨™: æ‰¾å‡ºè¨­è¨ˆç›¸é—œä¸”ä½¿ç”¨ vibe-coding å·¥å…·çš„æ¡ˆä¾‹")
    
    design_examples = []
    
    import time
    
    for i, case in enumerate(candidates[:30], 1):  # åˆ†æå‰ 30 å€‹
        print(f"\n[{i}/{min(len(candidates), 30)}] {case.get('title', 'N/A')[:60]}...")
        print(f"    è§€çœ‹æ•¸: {case.get('view_count', 0):,}")
        
        # æ·»åŠ å»¶é²ä»¥é¿å…è¶…é API é…é¡ï¼ˆæ¯åˆ†é˜ 10 æ¬¡ = æ¯ 7 ç§’ä¸€æ¬¡ï¼‰
        if i > 1:
            time.sleep(7)
        
        try:
            # æº–å‚™åˆ†æç”¨çš„æ•¸æ“šæ ¼å¼
            content = {
                'title': case.get('title', ''),
                'description': case.get('description', ''),
                'url': case.get('original_url', ''),
                'platform': 'YouTube',
                'creator': case.get('creator_name', ''),
                'creator_url': case.get('creator_link', ''),
                'thumbnail': case.get('thumbnail_url', ''),
            }
            
            analysis = crawler.analyze_with_ai(content)
            
            # æª¢æŸ¥æ˜¯å¦èˆ‡è¨­è¨ˆç›¸é—œ
            category_tags = analysis.get('category_tags', [])
            is_design_related = any(tag in ['Design', 'Design System', 'UI/UX', 'Web Design', 'UI', 'UX'] 
                                   for tag in category_tags)
            
            # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨äº†è¨­è¨ˆç›¸é—œçš„ vibe-coding å·¥å…·
            tools = analysis.get('ai_tools_used', [])
            has_design_tool = any(tool in ['Cursor', 'Figma', 'Figma Make', 'Figma MCP', 'Claude', 'ChatGPT', 'Lovable', 'v0'] 
                                for tool in tools)
            
            # æª¢æŸ¥æ˜¯å¦ç¢ºå¯¦æ§‹å»ºäº†é …ç›®
            is_real_project = analysis.get('is_real_project', False)
            project_evidence = analysis.get('project_evidence', '').lower()
            has_build_evidence = any(keyword in project_evidence for keyword in [
                'build', 'create', 'made', 'generated', 'developed'
            ])
            
            title_desc = (case.get('title', '') + ' ' + case.get('description', '')).lower()
            title_has_build = any(keyword in title_desc for keyword in [
                'build', 'create', 'made', 'built with', 'using cursor', 'using figma'
            ])
            
            # å¿…é ˆæ»¿è¶³æ‰€æœ‰æ¢ä»¶
            meets_criteria = (
                (is_design_related or has_design_tool) and
                has_design_tool and
                (is_real_project or has_build_evidence or title_has_build)
            )
            
            if meets_criteria:
                # æ›´æ–°æ¡ˆä¾‹çš„åˆ†é¡å’Œå·¥å…·ä¿¡æ¯
                case['primary_category'] = 'Design'
                case['ai_tools_used'] = tools
                case['category_tags'] = category_tags
                case['relevance_score'] = analysis.get('relevance_score', case.get('relevance_score', 7))
                case['build_complexity'] = analysis.get('build_complexity', case.get('build_complexity', 'Low-code'))
                case['is_real_project'] = is_real_project
                case['project_evidence'] = analysis.get('project_evidence', '')
                
                design_examples.append(case)
                print(f"  âœ… ç¬¦åˆæ¢ä»¶ï¼Œå·²æ›´æ–°ï¼ˆå·¥å…·: {tools}, åˆ†é¡: {category_tags}ï¼‰")
                
                if len(design_examples) >= 15:
                    print(f"\nâœ… å·²æ‰¾åˆ° 15 å€‹ç¬¦åˆæ¢ä»¶çš„æ¡ˆä¾‹ï¼Œåœæ­¢åˆ†æ")
                    break
            else:
                reasons = []
                if not is_design_related and not has_design_tool:
                    reasons.append("éè¨­è¨ˆç›¸é—œæˆ–æœªä½¿ç”¨è¨­è¨ˆå·¥å…·")
                if not has_design_tool:
                    reasons.append("æœªä½¿ç”¨ vibe-coding å·¥å…·")
                if not is_real_project and not has_build_evidence and not title_has_build:
                    reasons.append("ç„¡æ§‹å»ºè­‰æ“š")
                print(f"  âš ï¸  ä¸ç¬¦åˆæ¢ä»¶: {', '.join(reasons) if reasons else 'æœªçŸ¥'}")
                
        except Exception as e:
            print(f"  âŒ åˆ†æéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nâœ… æ‰¾åˆ° {len(design_examples)} å€‹ç¬¦åˆæ¢ä»¶çš„è¨­è¨ˆæ¡ˆä¾‹")
    
    # æ›´æ–°æ•¸æ“šåº«
    # æ‰¾å‡ºéœ€è¦æ›´æ–°çš„æ¡ˆä¾‹ï¼ˆæ ¹æ“š URLï¼‰
    updated_urls = {ex['original_url'] for ex in design_examples}
    
    # æ›´æ–°ç¾æœ‰æ•¸æ“š
    for i, item in enumerate(existing_data):
        if item.get('original_url') in updated_urls:
            # æ‰¾åˆ°å°æ‡‰çš„æ›´æ–°æ•¸æ“š
            updated_item = next((ex for ex in design_examples if ex['original_url'] == item['original_url']), None)
            if updated_item:
                existing_data[i] = updated_item
    
    # ä¿å­˜
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(existing_data, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'='*70}")
    print("âœ… å®Œæˆï¼")
    print(f"{'='*70}")
    print(f"  æ›´æ–°è¨­è¨ˆæ¡ˆä¾‹: {len(design_examples)}")
    print(f"  ç¸½æ¡ˆä¾‹æ•¸: {len(existing_data)}")
    print(f"\næ•¸æ“šå·²ä¿å­˜åˆ°: {data_file}")

if __name__ == "__main__":
    analyze_existing_youtube_cases()

